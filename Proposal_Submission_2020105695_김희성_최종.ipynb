{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eyetracker 만들기를 통한, 실제 보는 위치와 홍체의 움직임의 상관관계를  최소제곱근사를 통해 알아보기 \n",
    "\n",
    "#### 1.프로젝트의 목표 및 내용 :\n",
    "\n",
    "목표<br>\n",
    "0) eyetracker를 만들고, 이를 통해 동공의 위치와, 내가 보고 있는 실제 물체의 위치의 상관관계를 최소제곱근사를 통해 알아본다.<br>\n",
    "\n",
    "\n",
    "내용<br>\n",
    "1) 캠을 연결한 후, opencv를 이용하여 frame별로 동공의 위치값을 추정한다.<br>\n",
    "2) frame별로 추정한 동공의 위치값을 평균내어서, 실제 내가 보고있는 공간의 위치값과 대응시킨다. (많은 데이터를 만들기 위해 반복하여 데이터를 기록한다)<br>\n",
    "3) 데이터를 분석하여, 결과를 낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.주제 선정 이유 & 프로젝트의 필요성\n",
    "바꾼 이유 : <br>\n",
    "처음에는, 네이버 얼굴인식 API를 사용하였지만, 실시간적 변화를 이끌어 내지 못했다.<br>\n",
    "교수님이 상담중에 컴퓨터 비전과 opencv에 대해 말씀하셔서, 다시 조사해서 프로젝트를 진행하였다.<br>\n",
    "\n",
    "필요성 : <br>\n",
    "1. 사람의 주관적 감각을 수치화 한다는 점에서 의미가 있다. <br>\n",
    "사람의 감각은 정확한 정보를 받아들이기 어렵기 때문에, 이를 도울 프로그램이 필요하다. <br>\n",
    "내가 어느곳을 보고 있는지는 VR분야에도 중요하고, 이 외에 AR안경 등등 사용하는 분야가 무긍무진하다. <br>\n",
    "나중에 humeninteraction을 통해 사람의 감각이나 주관적인 정보를 직접 뇌에 연결하는 프로그램이 나오는 것의 전 단계라고 생각한다. <br>\n",
    "2. 사람이 어느 곳을 보고 있는지 알고 싶지만, 눈만 보고 3차원 공간상에서 어디를 보고 있는지 알 수 있는 공식을 찾지 못하겠다.<br>\n",
    "최소제곱근사를 통해서 컴퓨터로 인식되는 동공의 위치 값과, 내가 보고 있는 공간의 좌표 정보를 공식으로써 유도할 수 있는지 확인한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 데이터 획득\n",
    "1) 캠으로 동공의 위치를 입력받은 데이터 (많은 데이터로 평균 값을 사용할 것임.)\n",
    "영상을 30ms기준으로 frame별로 데이터를 입력받을 것이다. <br>\n",
    "\n",
    "x_l = 컴퓨터 화면으로 인식된, 왼쪽 눈의 x 좌표이다.<br>\n",
    "y_l = 컴퓨터 화면으로 인식된, 왼쪽 눈의 y좌표이다.<br>\n",
    "x_r = 컴퓨터 화면으로 인식된, 오른쪽 눈의 x좌표이다<br>\n",
    "y_r = 컴퓨터 화면으로 인식된, 오른쪽 눈의 y좌표이다.<br>\n",
    "\n",
    "정확한 인식을 위해, 3000ms frame 별로 찍은 data들을 약 5개 평균내서 얻는다.\n",
    "\n",
    "<img src=\"photograph/computerData.jpg\" width = \"300\" height=\"300\"> \n",
    "(인식 되는 것 확인)<br>\n",
    "\n",
    "<img src=\"photograph/데이터파일.jpg\" width=\"300\" height=\"300\">\n",
    "(데이터 사진)\n",
    " \n",
    "\n",
    "2) 실험 상황에서 직접 대상의 위치 데이터, (내가 직접 입력)\n",
    "\n",
    "<img src=\"photograph/실험setting.jpg\" width = \"300\" height=\"300\"><br>\n",
    "<img src=\"photograph/몸을 고정하기 위한 그림.jpg\" width = \"300\" height=\"300\"><br>\n",
    "<실험할 때 몸의 흔들림을 방지하기 위해, 뒤에 그린 그림><br>\n",
    "(실험 공간 사진)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 구현 내용 설명\n",
    "1) python의 opencv를 통해, 홍채가 검정색으로 인식 될 때, 관심 영역(Region of Interest, ROI)을 오른쪽 눈과 왼쪽 눈으로 맞춘다.<br>\n",
    "검은색으로 영상을 입력받고, 인식되는 검은색 부분을 binary image로 만든다.<br> \n",
    "threshold의 범위를 잘 설정해서, binary image(검은색과 하얀색 image)로 만든다.<br>\n",
    "(동공을 인식 시키고 싶었지만, 카메라의 성능이 홍채까지 검정색으로 인식하였다.)<br>\n",
    "\n",
    "2) contour를 통해 binary image의 흰색으로 검출 되는 부분을 검출한 후,그 좌표 값을 txt 파일로 저장한다.<br>(contour가 2개가 인식되는 경우, 다시 데이터를 획득한다. 가장 큰 contour만 인식되게 하는 것은 아직 구현하지 못했다.)<br>\n",
    "컴퓨터를 통해 동공의 위치를 입력받고, 데이터들을 평균내어 기록한다.<br>\n",
    "벽에 몸을 붙힌체, 떨어진 곳의 상대적 좌표값을 구한다.<br>\n",
    "\n",
    "내가 얻은 총 데이터의 양은 약 6개이다<br>\n",
    "(경계값을 위주로 내가 볼 수 있는 오른쪽 끝의 좌표값과 왼쪽끝의 좌표값 위쪽끝 좌표값,, 등등)<br>\n",
    "\n",
    "\n",
    "<img scr=\"\" width = \"300\" height=\"300\">\n",
    "위 사진과 같은 곳에 몸을 고정한다.<br>\n",
    "현재 실험과정에서는 캠과 내 눈사이 지점 사이 거리가 58cm이다.<br>\n",
    "(이것에 따라 실험이 달라질 수 있으니 고정하여 실험한다,)<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "3) 최소제곱근사를 활용해본다.\n",
    "3차원 eye tracker에서 우리가 측정할 것은 캠 위에서의 흰색 부분의 xyz 좌표 변화이다.<br>\n",
    "내가 보고있는 곳과, 캠에서 측정된 상대적 좌표 두 변수간의 상대적관계가 있는지 최소제곱정리를 통해 확인해본다.<br>\n",
    "\n",
    "x_l = 컴퓨터 화면으로 인식된, 왼쪽 눈의 x 좌표이다.<br>\n",
    "y_l = 컴퓨터 화면으로 인식된, 왼쪽 눈의 y좌표이다.<br>\n",
    "x_r = 컴퓨터 화면으로 인식된, 오른쪽 눈의 x좌표이다<br>\n",
    "y_r = 컴퓨터 화면으로 인식된, 오른쪽 눈의 y좌표이다.<br>\n",
    "\n",
    "내가 보고 있는 곳의 좌표를 내 턱 아래를 기준으로, vec{x,y,z}만큼 떨어져있다.<br>\n",
    "\n",
    "내가 직접 보고 있는 곳의 좌표의 성분과, 컴퓨터에 인식된 자료들의 어떤 관계가 있는지 최소 제곱근사를 통해 알아본다.<br>\n",
    "x_l,y_l,x_r,y_r 가 독립적인 성분으로 이루어져 있다고 가정하고, <br>\n",
    "\n",
    "1.<br>\n",
    "a_1(x_l) + b_1(y_l) + c_1(x_r) + d_1(y_r) = vec{x}<br>\n",
    "2.<br>\n",
    "a_2(x_l) + b_2(y_l) + c_2(x_r) + d_2(y_r) = vec{y}<br>\n",
    "3.<br>\n",
    "a_3(x_l) + b_3(y_l) + c_3(x_r) + d_3(y_r) = vec{z}<br>\n",
    "\n",
    "위의 세 식의 a,b,c,d의 값을 각각 최소제곱근사를 통해 구해본다.\n",
    "\n",
    "<img src = \"photograph/그림 설명.jpg\" width=\"800\" height=\"300\">\n",
    "그림을 통한 설명\n",
    "\n",
    "4) 위의 방정식을 유도하고, 이 방정식으로 다른 값을 예측 하는 것이 가능한지 확인한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.분석 결과 또는 구현 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "많은 데이터를 분석하지는 못했다. (6개, 길이를 정확히 측정하기 어렵기 때문,,)<br>\n",
    "아래 나오는 최소제곱근사 모델의 결과이다.,<br>\n",
    "시각화 하기 위해서는 r에 대한 변수를 2개를 변수 R로 치환하고<br>\n",
    "l에 대한 변수 2개를 L로 치환하고,<br>\n",
    "3차원 공간에 나타낸 다음 scatter형으로 나타내야할 것 같다.<br> (다음에 구현해 보겠습니다..)\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "아래와 같이 표현이 가능했다.<br>\n",
    "변수 4개에 대한 식이 하나의 변수를 결정했다.<br>\n",
    "\n",
    "Domain/ 정의역<br>\n",
    "[[18.9837 12.4674 34.5652 14.4185]<br>\n",
    " [14.25   17.5372 20.6064 17.4202]<br>\n",
    " [29.4106 14.2236 36.2236 15.2602]<br>\n",
    " [21.3688 20.7234 34.227  20.7021]<br>\n",
    " [12.2756 13.9843 30.1732 14.3228]<br>\n",
    " [19.044  28.326  39.     28.8352]]<br>\n",
    "real의 x에 대한 열벡터<br>\n",
    "[-75.  46.   0.   0.   0.   0.]<br>\n",
    "[  2.56410784  39.2803433   -1.80713928 -37.79767225]<br>\n",
    "다음 방정식을 최소제곱 근사 한 결과.<br>\n",
    "<br>\n",
    " 2.5641078443147274)x_r+39.280343296081575y_r+-1.8071392830124375x_l+-37.79767225128475y_l = vec(x)<br>\n",
    "식으로 근사 할 수 있다. <br>\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "Domain/ 정의역<br>\n",
    "[[18.9837 12.4674 34.5652 14.4185]<br>\n",
    " [14.25   17.5372 20.6064 17.4202]<br>\n",
    " [29.4106 14.2236 36.2236 15.2602]<br>\n",
    " [21.3688 20.7234 34.227  20.7021]<br>\n",
    " [12.2756 13.9843 30.1732 14.3228]<br>\n",
    " [19.044  28.326  39.     28.8352]]<br>\n",
    "real의 x에 대한 열벡터<br>\n",
    "[10. 31. 40. 92. 63.  7.]<br>\n",
    "[ -0.14924861  59.47813202   5.83761712 -65.45479227]<br>\n",
    "다음 방정식을 최소제곱 근사 한 결과.<br><br>\n",
    " -0.1492486109221498)x_r+59.478132023955595y_r+5.83761712377559x_l+-65.4547922745532y_l = vec(y)<br>\n",
    "식으로 근사 할 수 있다. <br>\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "Domain/ 정의역<br>\n",
    "[[18.9837 12.4674 34.5652 14.4185]<br>\n",
    " [14.25   17.5372 20.6064 17.4202]<br>\n",
    " [29.4106 14.2236 36.2236 15.2602]<br>\n",
    " [21.3688 20.7234 34.227  20.7021]<br>\n",
    " [12.2756 13.9843 30.1732 14.3228]<br>\n",
    " [19.044  28.326  39.     28.8352]]<br>\n",
    "real의 x에 대한 열벡터<br>\n",
    "[-40. -32. -34.   0.  45.   0.]<br>\n",
    "[ -5.29460863  42.25943452   6.31050023 -46.92309204]<br>\n",
    "다음 방정식을 최소제곱 근사 한 결과.<br><br>\n",
    " -5.294608633943855)x_r+42.25943452253663y_r+6.310500233762826x_l+-46.92309203503021y_l = vec(z)<br>\n",
    "식으로 근사 할 수 있다.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.결론\n",
    "결과 값이 나오긴 했지만, 많이 부족했다.<br>\n",
    "#### 아쉬운점\n",
    "eyetracker에 관한 식이 저렇게 독립적인 성분으로 이루어지지 않았을 수 있으며, 오차가 너무 컷다<br>\n",
    "변인 통제를 제대로 할 수 없었다. 홍채의 크기 빛의 량 시력 데이터의 양 모두 주관적인 것이 많았다. 좀 더 의미있는 결과를 내기 위해서는 변인 통제를 잘해야 할것이다.<br>\n",
    "그리고 모르는 사이 2개의 contour이 인식되면 다시 데이터를 얻어야 하는 불편함도 있었다.<br>\n",
    "고개를 돌려 각도를 맞추는 과정에서, 실험적 오차가 많이 발생한 것 같다.<br>\n",
    "또한, 다른 곳을 보면서(실험하면서) 데이터가 1개만 잘 관측되고 있는지 확인하기 힘들었다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.오픈소스 활용한 부분 명시\n",
    "\n",
    "유튜브 링크 https://www.youtube.com/watch?v=kbdbZFT9NQI&t=1164s <br>\n",
    "주소 https://pysource.com/2019/01/04/eye-motion-tracking-opencv-with-python/\n",
    "\n",
    "처음부터 그대로 따라하니깐 오류나서, 많이 고쳤다.<br>\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "cap = cv2.VideoCapture(\"eye_recording.flv\")\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret is False:\n",
    "        break\n",
    "    roi = frame[269: 795, 537: 1416]\n",
    "    rows, cols, _ = roi.shape\n",
    "    gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    gray_roi = cv2.GaussianBlur(gray_roi, (7, 7), 0)\n",
    "    gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    gray_roi = cv2.GaussianBlur(gray_roi, (7, 7), 0)\n",
    "    _, threshold = cv2.threshold(gray_roi, 3, 255, cv2.THRESH_BINARY_INV)\n",
    "    _, contours, _ = cv2.findContours(threshold, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key=lambda x: cv2.contourArea(x), reverse=True)\n",
    "    for cnt in contours:\n",
    "        (x, y, w, h) = cv2.boundingRect(cnt)\n",
    "        #cv2.drawContours(roi, [cnt], -1, (0, 0, 255), 3)\n",
    "        cv2.rectangle(roi, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "        cv2.line(roi, (x + int(w/2), 0), (x + int(w/2), rows), (0, 255, 0), 2)\n",
    "        cv2.line(roi, (0, y + int(h/2)), (cols, y + int(h/2)), (0, 255, 0), 2)\n",
    "        break\n",
    "    cv2.imshow(\"Threshold\", threshold)\n",
    "    cv2.imshow(\"gray roi\", gray_roi)\n",
    "    cv2.imshow(\"Roi\", roi)\n",
    "    key = cv2.waitKey(30)\n",
    "    \n",
    "    if key == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left eye\n",
      "34.5652,14.4185\n",
      "\n",
      "20.6064,17.4202\n",
      "\n",
      "36.2236,15.2602\n",
      "\n",
      "34.227,20.7021\n",
      "\n",
      "30.1732,14.3228\n",
      "\n",
      "39.0,28.8352\n",
      "\n",
      "\n",
      "\n",
      " right eye\n",
      "18.9837,12.4674\n",
      "\n",
      "14.25,17.5372\n",
      "\n",
      "29.4106,14.2236\n",
      "\n",
      "21.3688,20.7234\n",
      "\n",
      "12.2756,13.9843\n",
      "\n",
      "19.044,28.326\n",
      "\n",
      "\n",
      "\n",
      " real Distance\n",
      "-75,10,-40\n",
      "\n",
      "46,31,-32\n",
      "\n",
      "0,40,-34\n",
      "\n",
      "0,92,0\n",
      "\n",
      "0,63,45\n",
      "\n",
      "0,7,0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "데이터를 얻는 프로그램 & 분석하는 프로그램임.\n",
    "실제 떨어진 좌표 값 데이터는 스스로 입력해야함.\n",
    "나는 실제6개의 경계 값에 대해서 실험을 진행해봄\n",
    "\n",
    "(-75 -10 -40)#좌\n",
    "(46   31 -32)#우\n",
    "(0 40  -34)#아래\n",
    "(0 63 45)#위\n",
    "(0,7,0) #눈 바로 앞\n",
    "0,92,0 앞에 멀리 있는 물체\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "with open(\"dataFile/leftComputerData.txt\",\"r\") as a:\n",
    "    with open(\"dataFile/rightComputerData.txt\",\"r\") as b:\n",
    "        with open(\"dataFile/realValue.txt\",\"r\") as c:\n",
    "            print(\"left eye\")\n",
    "            for k in a:\n",
    "                print(k)\n",
    "            print(\"\\n\\n right eye\")\n",
    "            for u in b:\n",
    "                print(u)\n",
    "            print(\"\\n\\n real Distance\")\n",
    "            for z in c:\n",
    "                print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.별첨: 프로젝트를 위해 본인이 직접 개발한 python 소스코드 원본\n",
    "eyetacker 구현과, 이를 통한 데이터 획득 그리고 분석, 포멧, 저장.<br>\n",
    "main.ipynb를 통해 직접 실행 가능\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "print(\"we are going to get data, position of eye please set up the Roi\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "rightComputerValue = [] #we are going to send the date, which is the position of eye\n",
    "leftComputerValue = [] #we are going to send the date, which is the position of eye\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read() \n",
    "    roi = frame\n",
    "    \n",
    "    rightRoi = frame[250:300,250:300] # if you want to change the roi, change this list[rows,cols]\n",
    "    leftRoi = frame[250:300,300:350] # if you want to change the roi, change the list[rows,cols]\n",
    "    \n",
    "    roiGray = cv2.cvtColor(roi,cv2.COLOR_BGR2GRAY)\n",
    "    rightRoiGray = cv2.cvtColor(rightRoi,cv2.COLOR_BGR2GRAY)\n",
    "    leftROIGray = cv2.cvtColor(leftRoi,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    _, roiThreshold = cv2.threshold(roiGray,37,255,cv2.THRESH_BINARY_INV)\n",
    "    _, rightThreshold = cv2.threshold(rightRoiGray,37,255,cv2.THRESH_BINARY_INV)\n",
    "    _, leftThreshold = cv2.threshold(leftROIGray,37,255,cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    blurRoiThreshold = cv2.GaussianBlur(roiThreshold,(7,7),0)\n",
    "    blurRightThreshold = cv2.GaussianBlur(rightThreshold,(7,7),0)\n",
    "    blurLeftThreshold = cv2.GaussianBlur(leftThreshold,(7,7),0)\n",
    "    \n",
    "    rightContour,_ = cv2.findContours(blurRightThreshold,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    leftContour,_ = cv2.findContours(blurLeftThreshold,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    \n",
    "    if ret:\n",
    "        rows,cols,_ = roi.shape\n",
    "        rightRows,rightCols,_ = rightRoi.shape\n",
    "        leftRows,leftCols,_ = leftRoi.shape\n",
    "        \n",
    "        for rightCnt in rightContour:\n",
    "            (x_r,y_r,w_r,h_r) = cv2.boundingRect(rightCnt)\n",
    "            \n",
    "            cv2.drawContours(rightRoi,[rightCnt],-1,(0,0,255),1)\n",
    "            cv2.rectangle(rightRoi,(x_r,y_r),(x_r+w_r,y_r+h_r),(255,0,0),1)\n",
    "            \n",
    "            cv2.line(rightRoi,(x_r+int(w_r/2),0),(x_r+int(w_r/2),rightRows),(0,255,0),2)\n",
    "            cv2.line(rightRoi,(0,y_r+int(h_r/2)),(rightCols,y_r+int(h_r/2)),(0,255,0),2)\n",
    "        \n",
    "        \n",
    "        for leftCnt in leftContour:\n",
    "            (x_l,y_l,w_l,h_l) = cv2.boundingRect(leftCnt)\n",
    "            \n",
    "            cv2.drawContours(leftRoi,[leftCnt],-1,(0,0,255),1)\n",
    "            cv2.rectangle(leftRoi,(x_l,y_l),(x_l+w_l,y_l+h_l),(255,0,0),1)\n",
    "            \n",
    "            cv2.line(leftRoi,(x_l+int(w_l/2),0),(x_l+int(w_l/2),leftRows),(0,255,0),2)\n",
    "            cv2.line(leftRoi,(0,y_l+int(h_l/2)),(leftCols,y_l+int(h_l/2)),(0,255,0),2)\n",
    "        \n",
    "        \n",
    "\n",
    "        cv2.imshow(\"Roi\",roi)\n",
    "        cv2.imshow(\"rightEye\",rightRoi)\n",
    "        cv2.imshow(\"leftEye\",leftRoi)\n",
    "        cv2.imshow(\"roiBinary\",blurRoiThreshold)\n",
    "        cv2.imshow(\"rightBinary\",blurRightThreshold)\n",
    "        cv2.imshow(\"leftBinary\",blurLeftThreshold)\n",
    "        \n",
    "        \n",
    "        rightPosition=[x_r+int(w_r/2),y_r+int(h_r/2)]\n",
    "        leftPosition=[x_l+int(w_l/2),y_l+int(h_l/2)]\n",
    "        print(\"present right eye position\",rightPosition,\"\\n present left eye position\",leftPosition)\n",
    "        \n",
    "        rightComputerValue.append(rightPosition)\n",
    "        leftComputerValue.append(leftPosition)\n",
    "        \n",
    "        key = cv2.waitKey(30) #if you want to change the time of frame change this waitKey(time)\n",
    "        if key == 27:\n",
    "            break\n",
    "        \n",
    "cap.release()            \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(rightComputerValue)\n",
    "print(leftComputerValue)\n",
    "\n",
    "#sendcode\n",
    "def average(lst):\n",
    "    \"\"\"list in list->list #(inner list's lenth is 2)\n",
    "    \n",
    "    return the average of each index\n",
    "    \n",
    "    ex)\n",
    "    >>>average([[0,5],[1,7],[2,9],[3,11],[4,13]])\n",
    "    >>>[2,9] # float round 4\n",
    "    \"\"\"\n",
    "    first, second = 0,0\n",
    "    for k in lst:\n",
    "        first += k[0]\n",
    "        second += k[1]\n",
    "        first_av = first/len(lst)\n",
    "        second_av = second/len(lst)\n",
    "    result = [round(first_av,4),round(second_av,4)]\n",
    "    return result\n",
    "\n",
    "\n",
    "rightComputerData = average(rightComputerValue)\n",
    "leftComputerData = average(leftComputerValue)\n",
    "\n",
    "\n",
    "while True:\n",
    "    print(\"\\n\\n\\n\",rightComputerData,\"is right Data\")\n",
    "    print(leftComputerData,\"is left Data\")\n",
    "    whether = input(\"this Data is proper? y/n \")\n",
    "    \n",
    "    if whether == \"y\":\n",
    "        with open(\"dataFile/rightComputerData.txt\",\"a\") as Rcomputer:\n",
    "            with open(\"dataFile/leftComputerData.txt\",\"a\") as Lcomputer:\n",
    "                with open(\"dataFile/realValue.txt\",\"a\") as real:\n",
    "                    relative_coordinate_value = input(\"PLZ give me the position of relative coordinate value \\n using csv value ex) 1,2,3 \\n use meter unit\")\n",
    "                    \n",
    "                    a=input(f\"{relative_coordinate_value}is that True? y/n\")\n",
    "                    if a ==\"y\":\n",
    "                        Rcomputer.write(f\"{rightComputerData[0]},{rightComputerData[1]}\\n\")\n",
    "                        Lcomputer.write(f\"{leftComputerData[0]},{leftComputerData[1]}\\n\")\n",
    "                        real.write(f\"{relative_coordinate_value}\\n\")\n",
    "                        print(\"Data updated\")\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "    elif whether == \"n\":\n",
    "        break\n",
    "    else:\n",
    "        print(\"PLZ re try\")\n",
    "        continue\n",
    "```\n",
    "<hr>\n",
    "\n",
    "데이터 초기화\n",
    "```python\n",
    "print(\"If you want to format the data, road this\")\n",
    "re = input(\"really? y/n\")\n",
    "if re == \"y\":\n",
    "    with open(\"dataFile/rightComputerData.txt\",\"w\") as Rcomputer:\n",
    "        with open(\"dataFile/leftComputerData.txt\",\"w\") as Lcomputer:\n",
    "            with open(\"dataFile/realValue.txt\",\"w\") as real:\n",
    "                Rcomputer.write(\"\")\n",
    "                Lcomputer.write(\"\")\n",
    "                real.write(\"\")\n",
    "                print(\"Data updated\")\n",
    "else:\n",
    "    \"Try again\"\n",
    "\n",
    "````\n",
    "\n",
    "<hr>\n",
    "\n",
    "최소제곱근사 모델\n",
    "```python\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def changeFloat(lst):\n",
    "    \"\"\"list->list\n",
    "    change string list to float list \n",
    "    \"\"\"\n",
    "    resultList=[]\n",
    "    for k in lst:\n",
    "        resultList.append(float(k))\n",
    "    return resultList\n",
    "\n",
    "#real vec{x}에 관한 방정식 유도,\n",
    "with open(\"dataFile/rightComputerData.txt\",\"r\") as a:\n",
    "    with open(\"dataFile/leftComputerData.txt\",\"r\") as b:\n",
    "        with open(\"dataFile/realValue.txt\",\"r\") as c:\n",
    "            Metrix=[]\n",
    "            vec=[]\n",
    "            for afileContent in a:\n",
    "                bfileContent= \",\"+b.readline()\n",
    "                testrow=afileContent+bfileContent\n",
    "                stringrow = testrow.strip().split(\",\")\n",
    "                row = changeFloat(stringrow)\n",
    "                Metrix.append(row)\n",
    "                stringImg = c.readline()\n",
    "                lstImg = stringImg.strip().split(\",\")\n",
    "                vec.append(changeFloat(lstImg)[0])\n",
    "            \n",
    "            V=np.array(Metrix)\n",
    "            w=np.array(vec)\n",
    "            print(\"Domain/ 정의역\",V,\"real의 x에 대한 열벡터\",w,sep=\"\\n\")\n",
    "            \n",
    "            displace=np.dot(V.transpose(),V)\n",
    "            displace2=np.dot(np.linalg.inv(displace),V.transpose())\n",
    "            kernel = np.dot(displace2,w)\n",
    "            print(kernel)\n",
    "            print(f\"다음 방정식을 최소제곱 근사 한 결과.\\n {kernel[0]})x_r+{kernel[1]}y_r+{kernel[2]}x_l+{kernel[3]}y_l = vec(x)\")\n",
    "            print(\"식으로 근사 할 수 있다. \\n\\n\\n\\n\")\n",
    "\n",
    "with open(\"dataFile/rightComputerData.txt\",\"r\") as d:\n",
    "    with open(\"dataFile/leftComputerData.txt\",\"r\") as e:\n",
    "        with open(\"dataFile/realValue.txt\",\"r\") as f:\n",
    "            Metrix=[]\n",
    "            vec=[]\n",
    "            for afileContent in d:\n",
    "                bfileContent= \",\"+e.readline()\n",
    "                testrow=afileContent+bfileContent\n",
    "                stringrow = testrow.strip().split(\",\")\n",
    "                row = changeFloat(stringrow)\n",
    "                Metrix.append(row)\n",
    "                stringImg = f.readline()\n",
    "                lstImg = stringImg.strip().split(\",\")\n",
    "                vec.append(changeFloat(lstImg)[1])\n",
    "            \n",
    "            V=np.array(Metrix)\n",
    "            w=np.array(vec)\n",
    "            print(\"Domain/ 정의역\",V,\"real의 x에 대한 열벡터\",w,sep=\"\\n\")\n",
    "            \n",
    "            displace=np.dot(V.transpose(),V)\n",
    "            displace2=np.dot(np.linalg.inv(displace),V.transpose())\n",
    "            kernel = np.dot(displace2,w)\n",
    "            print(kernel)\n",
    "            print(f\"다음 방정식을 최소제곱 근사 한 결과.\\n {kernel[0]})x_r+{kernel[1]}y_r+{kernel[2]}x_l+{kernel[3]}y_l = vec(y)\")\n",
    "            print(\"식으로 근사 할 수 있다. \\n\\n\\n\\n\")\n",
    "\n",
    "with open(\"dataFile/rightComputerData.txt\",\"r\") as e:\n",
    "    with open(\"dataFile/leftComputerData.txt\",\"r\") as f:\n",
    "        with open(\"dataFile/realValue.txt\",\"r\") as g:\n",
    "            Metrix=[]\n",
    "            vec=[]\n",
    "            for afileContent in e:\n",
    "                bfileContent= \",\"+f.readline()\n",
    "                testrow=afileContent+bfileContent\n",
    "                stringrow = testrow.strip().split(\",\")\n",
    "                row = changeFloat(stringrow)\n",
    "                Metrix.append(row)\n",
    "                stringImg = g.readline()\n",
    "                lstImg = stringImg.strip().split(\",\")\n",
    "                vec.append(changeFloat(lstImg)[2])\n",
    "            \n",
    "            V=np.array(Metrix)\n",
    "            w=np.array(vec)\n",
    "            print(\"Domain/ 정의역\",V,\"real의 x에 대한 열벡터\",w,sep=\"\\n\")\n",
    "            \n",
    "            displace=np.dot(V.transpose(),V)\n",
    "            displace2=np.dot(np.linalg.inv(displace),V.transpose())\n",
    "            kernel = np.dot(displace2,w)\n",
    "            print(kernel)\n",
    "            print(f\"다음 방정식을 최소제곱 근사 한 결과.\\n {kernel[0]})x_r+{kernel[1]}y_r+{kernel[2]}x_l+{kernel[3]}y_l = vec(z)\")\n",
    "            print(\"식으로 근사 할 수 있다.\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 억울하지만 갈아 엎은 파일들...\n",
    "\n",
    "처음엔 네이버 얼굴인식 API를 사용하려고 하였다.\n",
    "\n",
    "1. 캠으로 영상을 찍고(Iriun Webcam), 이를 frame 단위로 분석한다. (이때 네이버 얼굴인식 api를 사용한다.)<br>\n",
    "\n",
    "2. 영상을 다운받고(osb Studio), 초단위로 (곰플레이어)를 통해 쪼갠다.  <br>\n",
    "\n",
    "\n",
    "3. 데이터를 분석해 본다.\n",
    "\n",
    "\n",
    "또한 pygaze라는 오픈소스로 이용해서 하려고 했는데, 활용법을 잘 모르겠다.<br>\n",
    "그래서 oepncv로 갈아 타게 되었다.\n",
    "\n",
    "\n",
    "<img src = \"photograph/전에 하려고 했던 것2.jpg\" width=\"200\" height=\"200\">\n",
    "<img src = \"photograph/전에 하려고 했던것.jpg\" width=\"200\" height=\"200\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
