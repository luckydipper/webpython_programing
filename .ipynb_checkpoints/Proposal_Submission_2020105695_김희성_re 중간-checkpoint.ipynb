{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시각 인지 가능 범위 측정과, 동체 시력과 게임 실력관계\n",
    "\n",
    "#### 1.프로젝트의 목표 및 내용 :\n",
    "1. 캠으로 영상을 찍고, 이를 frame 단위로 분석한다. (이때 네이버 얼굴인식 api를 사용한다.)<br>\n",
    "\n",
    "2. 시각 인지가 어느 정도 범위까지 가능한지 테스트 해본다. <br>\n",
    "\n",
    "3. 시각인지 범위를 바탕으로 변화 눈의 위치의 변화 속도와, 가속도 값을 구해서 동체시력을 수치화 해본다 <br>\n",
    "\n",
    "4. 동체 시력을 이용하는 게임을, 처음하는 사람을 대상으로 하게한다음, 동체시력을 구해 게임 실력간의 연관성을 밝혀본다.<br>\n",
    "\n",
    "3. 공부적으로 가장 큰 목표는 행렬을 이용하는 것이다. 행렬을 이용해서 동체시력의 값을 정의해본다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.주제 선정 이유 & 프로젝트의 필요성\n",
    "바꾼 이유 : <br>\n",
    "\n",
    "처음에는 3차원 eyetracker를 만들어보려고 하였다. 즉, 캠을 통해 눈의 위치 값을 받고, 공간상에서 어디를 보고있는지 맞추는 프로그램을 만들려고 하였다.<br>\n",
    "그러나 실시간으로 영상을 받아 처리하는 과정이 어려워서, 녹화본을 이용하기로 하였고, 주제도 위와 같이 축소하게 되었다.<br>\n",
    "\n",
    "\n",
    "필요성 : <br>\n",
    "1. 사람의 주관적 감각을 수치화 한다는 점에서 의미가 있다. <br>\n",
    "사람의 감각은 정확한 정보를 받아들이기 어렵기 때문에, 이를 도울 프로그램이 필요하다. <br>\n",
    "내가 어느곳을 보고 있는지는 VR분야에도 중요하고, 이 외에 AR안경 등등 사용하는 분야가 무긍무진하다. <br>\n",
    "나중에 humeninteraction을 통해 사람의 감각이나 주관적인 정보를 직접 뇌에 연결하는 프로그램이 나오는 것의 전 단계라고 생각한다. <br>\n",
    "2. 게임을 하다보면, \"피지컬 차이\"라며, 정당화 하는 사람들의 말이 맞는지 알아 볼 수 있다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 데이터 획득\n",
    "1. \"Iriun Webcam\"혹은 노트북의 웹캠을 활용해서 통해 동영상을 찍는다.\n",
    "\n",
    "2. \"OBS\"를 통해 찍은 동영상을 저장한다.\n",
    "\n",
    "3. \"곰플레이어\"를 통해 찍은 동영상을 x초 단위로 분할하여, 저장한다. <이미지 데이터>\n",
    "\n",
    "4. 게임을 할 때의 점수와, 얼굴인식 api를 이용한 동체시력 data <통계 내야 하는 데이터> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 구현 내용 설명\n",
    "1. 이미지 데이터를 \"Iriun Webcam\"과 \"OBS\", \"곰플레이어\"를 통해 얻는다.\n",
    "<img src=\"자료1.jpg\" width=\"300\" height=\"300\">\n",
    "<img src=\"자료4.jpg\" width=\"300\" height=\"300\">\n",
    "2. t초 동안 영상을 찍을 때, 눈의 위치를 가 고정됐는지 확인하고, 평면 화면에서 한 곳을 고정시키고, 보이는 영역을 구한다. <br>\n",
    "ex) \"일정 공간 안을 당신이 보고 있습니까? 예 or 아니오\"로 인식할 수 있는 범위를 설정한다. 그리고 당신은 전방으로부터 '몇도' 만큼 떨어진 곳에 '몇미터 앞에' 'xyz 직사각형 부피 만큼의 공간 안을'을 인식하고 있다는 값을 출력한다.\n",
    "3. 동체시력이란 물체를 빠르고 정확하게 인식하는 능력이다. 이는 naver 얼굴인식 api에서 좌표값의 차이와 인식되는 공간의 곱으로 나타낼 것이다. <행렬을 이용해서>\n",
    "4. 동체시력의 값이 나오면, 친구들과 나를 이용해서 실험을 해볼 것이다.\n",
    "geometridash와 superhexagon 게임을 이용하여, 점수와 동체시력의 측정 값을 비교한다.\n",
    "<img src=\"자료6.jpg\" width=\"300\" height=\"300\">\n",
    "\n",
    "5. matplot pandas 를 이용해서 데이터를 분석하고 가설이 맞는 지 확인한다.\n",
    "\n",
    "ext.\n",
    "open source인 pygaze를 이용하는 것과<br>\n",
    "tensorflow 머신러닝 선형 회귀를 통한, 내 동공의 위치 값과 실체 물체의 위치값을이 어떤 관계를 갖는지 확인하는 것은 시간이 되는 경우 도전한다. <br>\n",
    "열심히 해보고 있지만 어려워서,,,\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.분석 결과 또는 구현 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom IPython.display import Image\\n![title](자료1.jpg){: width=\"100\" height=\"100\"}\\nImage(\"1.jpg\")\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from IPython.display import Image\n",
    "![title](자료1.jpg){: width=\"100\" height=\"100\"}\n",
    "Image(\"1.jpg\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"1.jpg\" width=\"300\" height=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"info\":{\"size\":{\"width\":1920,\"height\":1080},\"faceCount\":1},\"faces\":[{\"roi\":{\"x\":818,\"y\":402,\"width\":374,\"height\":374},\"landmark\":{\"leftEye\":{\"x\":912,\"y\":468},\"rightEye\":{\"x\":1091,\"y\":481},\"nose\":{\"x\":994,\"y\":556},\"leftMouth\":{\"x\":907,\"y\":666},\"rightMouth\":{\"x\":1054,\"y\":684}},\"gender\":{\"value\":\"male\",\"confidence\":0.978545},\"age\":{\"value\":\"23~27\",\"confidence\":0.631722},\"emotion\":{\"value\":\"neutral\",\"confidence\":0.663812},\"pose\":{\"value\":\"frontal_face\",\"confidence\":0.999849}}]}\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "#사진을 frame 단위로 쪼갠후, api를 이용하여 분석하는 모습이다. <naver clova face recognition을 이용하였다.>\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "client_id = \"Oiv30WKES7L7y2nUnf5f\"\n",
    "client_secret = \"vmTrnHOcp3\"\n",
    "url = \"https://openapi.naver.com/v1/vision/face\"\n",
    "for k in range(1,2):\n",
    "    files = {'image': open(f'{k}.jpg', 'rb')} #dictionary, 이진수로 읽는거\n",
    "    headers = {'X-Naver-Client-Id': client_id, 'X-Naver-Client-Secret': client_secret }\n",
    "    response = requests.post(url,  files=files, headers=headers)\n",
    "    rescode = response.status_code\n",
    "    if(rescode==200):\n",
    "        답 = response.text\n",
    "        print (response.text)\n",
    "        print(type(response.text))\n",
    "    else:\n",
    "        print(\"Error Code:\" + rescode)\n",
    "#이것을 slicing 해서 분석 할 것임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.결론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.오픈소스 활용한 부분 명시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.참고문헌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.별첨: 3)의 획득한 데이터 원본 (너무 큰 경우 링크)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.별첨: 4)의 가공한 데이터 원본"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.별첨: 프로젝트를 위해 본인이 직접 개발한 python 소스코드 원본"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "처음에 pygaze를 이용해서 오픈소스로 이용해서 하려고 했는데, 활용법을 잘 모르겠다. <br>\n",
    "그래서 \n",
    "\n",
    "- 인식의 범위를 측정해 보겠다.\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
